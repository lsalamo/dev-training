{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting patterns on leads \n",
    "\n",
    "We are going to play with the following dataset\n",
    "\n",
    "1.- **Dataset name to request access:** Insights-FactLayer-Leads\n",
    "\n",
    "2.- **Athena (SQLaaS):** {provider}_databox.insights_leads_fact_layer_90d.\n",
    "\n",
    "3.- **S3 path** s3://schibsted-spt-common-prod/yellow/insights/leads/\n",
    "\n",
    "[More information](https://docs.schibsted.io/data-and-insight/insights-pipelines/10.Data%20Model/fact-layer/#sessions-user-behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Needed packages\n",
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "access_key = getpass(prompt=\"Enter your access key to databox: \")\n",
    "secret_key = getpass(prompt=\"Enter your secret to databox: \")\n",
    "\n",
    "# Some parameters (another different way to extract the credential)\n",
    "user = \"maria.pelaez@schibsted.com/\"\n",
    "provider ='avitoma'\n",
    "\n",
    "# Doing the connection\n",
    "conn = connect(aws_access_key_id=access_key,\n",
    "               aws_secret_access_key=secret_key,\n",
    "               s3_staging_dir=\"s3://schibsted-spt-common-dev/user-areas/\"+ user,\n",
    "               region_name=\"eu-west-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Doing a simple query\n",
    "query_leads = \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  {}_databox.insights_leads_fact_layer_90d\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "df_leads = pd.read_sql(query_leads.format(provider), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_leads.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Doing a simple query\n",
    "leads = \"\"\"\n",
    "SELECT\n",
    " globalleadtype,\n",
    " published,\n",
    " count(globalleadtype) AS nof_leads\n",
    "FROM\n",
    "(\n",
    " SELECT\n",
    "   globalleadtype,\n",
    "   substring(published,1,10) as published\n",
    " FROM\n",
    "  {}_databox.insights_leads_fact_layer_90d  \n",
    ")\n",
    "GROUP BY \n",
    " globalleadtype,\n",
    " published\n",
    "\"\"\"\n",
    "df = pd.read_sql(leads.format(provider), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['globalleadtype'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare your data to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabla = df.pivot_table(index='published',columns='globalleadtype',values='nof_leads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabla.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots(1,1,figsize=(15,10))\n",
    "tabla.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Customize the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Improving the labels and adding title\n",
    "ax.set_xlabel(\"\")\n",
    "fig.suptitle('Evolution of leads per type',fontsize=20)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## fixing size of ticks\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modifying the legend\n",
    "ax.legend(loc='upper left',prop={'size':18})\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Un barplot\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['weekdate'] = pd.to_datetime(df['published']).dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = df.groupby(['weekdate'])['nof_leads'].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1**:\n",
    "\n",
    "Customize the previous graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 2**:\n",
    "\n",
    "* Create a query to extract number of lead types (sms, show phone etc.) grouped by vertical using `adlocalvertical` column\n",
    "* Create a chart to visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 3**:\n",
    "\n",
    "Now we are going to create two datasets: \n",
    "\n",
    "* All items with the number of classified ads from {provider}_databox.yellow_pulse_simple_1d (type = \"View\", objecttype = \"ClassifiedAd\")\n",
    "* All items with the number of leads\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_data1 = \"\"\"\n",
    "SELECT\n",
    " objectid,\n",
    " category,\n",
    " count(*) AS nof_adviews\n",
    "FROM\n",
    " {}_databox.yellow_pulse_simple_1d\n",
    "WHERE \n",
    " (type='View' and objecttype = 'ClassifiedAd')\n",
    "GROUP BY\n",
    " objectid,\n",
    " category\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "query_data2 = \"\"\"\n",
    "SELECT\n",
    "  objectid,\n",
    "  count(*) as_nof_leads\n",
    "FROM\n",
    " {}_databox.yellow_pulse_simple_1d\n",
    "WHERE \n",
    " (type='Call' and objecttype = 'PhoneContact') OR\n",
    " (type='Show' and objecttype = 'PhoneContact') OR\n",
    " (type='Send' and objecttype = 'Message') OR\n",
    " (type='SMS' and objecttype = 'PhoneContact')\n",
    "GROUP BY\n",
    " objectid\n",
    "\"\"\"\n",
    "adviews = pd.read_sql(query_data1.format(provider), conn)\n",
    "leads = pd.read_sql(query_data2.format(provider), conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute:\n",
    "    \n",
    "1) A new dataframe joining adviews and leads\n",
    "\n",
    "2) To compute the percentage of ads with leads per category\n",
    "\n",
    "3) How many ad views are needed to have at least one lead per category?\n",
    "\n",
    "\n",
    "**Hint**: Check [this](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) out to learn how to merge dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
